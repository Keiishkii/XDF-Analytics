{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pandas.core.interchange.dataframe_protocol import DataFrame\n",
    "%reset -f"
   ],
   "id": "4613ec878215169c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "from MINE.Log import Log\n",
    "from MINE.Analysis import SessionAnalytics, ExperimentAnalytics\n",
    "from MINE.StreamFilter import IStreamFilter, TimestampStreamFilter\n",
    "from MINE.SessionFilters import ISessionFilter, ContainsStreamSessionFilter, ContainsMarkersSessionFilter\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 300"
   ],
   "id": "89a8fb0c1088cb59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def stream_filter() -> ContainsStreamSessionFilter:\n",
    "    return ContainsStreamSessionFilter([\n",
    "        \"Marker\",\n",
    "        \"Av Rating Continuous\",\n",
    "        \"OcoSense_OCO_14640BA8E2DD [98BE107F-3760-7351-78D3-DFB1DE240AE5]\",\n",
    "        \"HR\"\n",
    "    ])\n",
    "\n",
    "def marker_filter() -> ContainsMarkersSessionFilter:\n",
    "    return ContainsMarkersSessionFilter(\"Marker\", [\n",
    "        \"Video: Be a floater, Event: VideoStart\",\n",
    "        \"Video: Be a floater, Event: VideoEnd\",\n",
    "        \"Video: RNLI Respect the water “Ladbible short film”, Event: VideoStart\",\n",
    "        \"Video: RNLI Respect the water “Ladbible short film”, Event: VideoEnd\",\n",
    "        \"Video: “Evans story”, Event: VideoStart\",\n",
    "        \"Video: “Evans story”, Event: VideoEnd\",\n",
    "        \"Video: “Little girl being rescued by RNLI”, Event: VideoStart\",\n",
    "        \"Video: “Little girl being rescued by RNLI”, Event: VideoEnd\",\n",
    "        \"Video: Alfie’s phone, Event: VideoStart\",\n",
    "        \"Video: Alfie’s phone, Event: VideoEnd\",\n",
    "        \"Video: “Float to Live”, Event: VideoStart\",\n",
    "        \"Video: “Float to Live”, Event: VideoEnd\",\n",
    "        \"Video: Respect the Water via the NWSF\\u202f‘make the right call’, Event: VideoStart\",\n",
    "        \"Video: Respect the Water via the NWSF\\u202f‘make the right call’, Event: VideoEnd\",\n",
    "        \"Video: “Seaside safety song”, Event: VideoStart\",\n",
    "        \"Video: “Seaside safety song”, Event: VideoEnd\",\n",
    "        \"Video: RNLI the breath test, Event: VideoStart\",\n",
    "        \"Video: RNLI the breath test, Event: VideoEnd\",\n",
    "        \"Video: RNLI Christmas bed-time story, Event: VideoStart\",\n",
    "        \"Video: RNLI Christmas bed-time story, Event: VideoEnd\",\n",
    "        \"Video: “RNLI: The heart-breaking story of Liam Hall”, Event: VideoStart\",\n",
    "        \"Video: “RNLI: The heart-breaking story of Liam Hall”, Event: VideoEnd\",\n",
    "    ])"
   ],
   "id": "3ac81e684fc7b9fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def video_data() -> pd.DataFrame:\n",
    "    return pd.DataFrame(columns=[\"Video_ID\", \"Video_Name\"], data=[\n",
    "        [\"Video 1\", \"Video: Be a floater\"],\n",
    "        [\"Video 2\", \"Video: RNLI Respect the water “Ladbible short film”\"],\n",
    "        [\"Video 3\", \"Video: “Evans story”\"],\n",
    "        [\"Video 4\", \"Video: “Little girl being rescued by RNLI”\"],\n",
    "        [\"Video 5\", \"Video: Alfie’s phone\"],\n",
    "        [\"Video 6\", \"Video: “Float to Live”\"],\n",
    "        [\"Video 7\", \"Video: Respect the Water via the NWSF\\u202f‘make the right call’\"],\n",
    "        [\"Video 8\", \"Video: “Seaside safety song”\"],\n",
    "        [\"Video 9\", \"Video: RNLI the breath test\"],\n",
    "        [\"Video 10\", \"Video: RNLI Christmas bed-time story\"],\n",
    "        [\"Video 11\", \"Video: “RNLI: The heart-breaking story of Liam Hall”\"],\n",
    "    ])\n",
    "\n",
    "def participant_data() -> pd.DataFrame:\n",
    "     return pd.DataFrame(columns=[\"Participant_ID\", \"File_Path\"], data=[\n",
    "         [\"P01 - 535679\", \"V:/Data/Analysis/RNLI/participant 1.xdf\"],\n",
    "         [\"P02 - 888462\", \"V:/Data/Analysis/RNLI/participant 2.xdf\"],\n",
    "         [\"P03 - 499031\", \"V:/Data/Analysis/RNLI/participant 3.xdf\"],\n",
    "         [\"P04.0 - 832362\", \"V:/Data/Analysis/RNLI/participant 4.0.xdf\"],\n",
    "         [\"P04.1 - 832362\", \"V:/Data/Analysis/RNLI/participant 4.1.xdf\"],\n",
    "         [\"P05\", \"V:/Data/Analysis/RNLI/participant 5.xdf\"],\n",
    "         [\"P06\", \"V:/Data/Analysis/RNLI/participant 6.xdf\"],\n",
    "         [\"P07\", \"V:/Data/Analysis/RNLI/participant 7.xdf\"],\n",
    "         [\"P08\", \"V:/Data/Analysis/RNLI/participant 8.xdf\"],\n",
    "         [\"P09\", \"V:/Data/Analysis/RNLI/participant 9.xdf\"],\n",
    "         [\"P10 - 999149\", \"V:/Data/Analysis/RNLI/participant 10.xdf\"],\n",
    "         [\"P11 - 153327\", \"V:/Data/Analysis/RNLI/participant 11.xdf\"],\n",
    "         [\"P12\", \"V:/Data/Analysis/RNLI/participant 12.xdf\"],\n",
    "         [\"P13\", \"V:/Data/Analysis/RNLI/participant 13.xdf\"],\n",
    "         [\"P14\", \"V:/Data/Analysis/RNLI/participant 14.xdf\"],\n",
    "         [\"P15 - 156103\", \"V:/Data/Analysis/RNLI/participant 15.xdf\"],\n",
    "         [\"P16 - 701399\", \"V:/Data/Analysis/RNLI/participant 16.xdf\"]\n",
    "     ])"
   ],
   "id": "da40ae78dd6cb702",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_experiment_analytics: ExperimentAnalytics = ExperimentAnalytics.create_from_paths(participant_data())\n",
    "_experiment_analytics: ExperimentAnalytics = _experiment_analytics.get_filtered_subset([\n",
    "    marker_filter(),\n",
    "    stream_filter()\n",
    "])"
   ],
   "id": "23d50369ea986a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def add_stream_values(session_analytics: SessionAnalytics, videos: pd.DataFrame, video_name: str, stream_name: str, start: float, end: float, normalised_time: bool = False):\n",
    "    timestamp_filter = TimestampStreamFilter(start, end)\n",
    "    subset_analytics = session_analytics.get_filtered_subset(timestamp_filter)\n",
    "\n",
    "    stream_subset = subset_analytics.stream_data_dictionary[stream_name]\n",
    "\n",
    "    values = stream_subset[\"Value\"].tolist()\n",
    "    timestamps = stream_subset[\"Timestamp\"].tolist()\n",
    "    normalised_timestamps = timestamps - start\n",
    "\n",
    "    if f\"{stream_name}_Timestamps\" not in videos: videos[f\"{stream_name}_Timestamps\"] = pd.Series(dtype=object)\n",
    "    if f\"{stream_name}_Values\" not in videos: videos[f\"{stream_name}_Values\"] = pd.Series(dtype=object)\n",
    "\n",
    "    row_index = videos.index[videos['Video_Name'] == video_name].to_list()[0]\n",
    "    videos.at[row_index, f\"{stream_name}_Timestamps\"] = normalised_timestamps if normalised_time else timestamps\n",
    "    videos.at[row_index, f\"{stream_name}_Values\"] = values\n",
    "\n",
    "def populate_video_data(session_analytics: SessionAnalytics, videos: pd.DataFrame):\n",
    "    marker_pairs = session_analytics.get_paired_markers(\"Marker\", \"VideoStart\", \"VideoEnd\")\n",
    "\n",
    "    # Add in the timestamp data to the dataframe\n",
    "    for _, video_row in videos.iterrows():\n",
    "        video_name = video_row.loc[\"Video_Name\"]\n",
    "        marker_row = marker_pairs[marker_pairs[\"Start Marker\"].str.contains(video_name, regex=False)]\n",
    "\n",
    "        start_time = marker_row[\"Start Timestamp\"].iloc[0]\n",
    "        end_time = marker_row[\"End Timestamp\"].iloc[0]\n",
    "\n",
    "        videos.loc[videos['Video_Name'] == video_name, 'Start_Timestamp'] = start_time\n",
    "        videos.loc[videos['Video_Name'] == video_name, 'End_Timestamp'] = end_time\n",
    "\n",
    "        add_stream_values(session_analytics, videos, video_name, \"PPG_GRN\", start_time, end_time, normalised_time=True)\n",
    "        add_stream_values(session_analytics, videos, video_name, \"PPG_RED\", start_time, end_time, normalised_time=True)\n",
    "        add_stream_values(session_analytics, videos, video_name, \"PPG_IR\", start_time, end_time, normalised_time=True)"
   ],
   "id": "8a4969381ac30d80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_maximum_timestamp(videos: pd.DataFrame) -> float:\n",
    "    maximum_timestamp: float = 0\n",
    "    for _, video_row in videos.iterrows():\n",
    "        maximum_green_timestamp = max(video_row[\"PPG_GRN_Timestamps\"])\n",
    "        maximum_red_timestamp = max(video_row[\"PPG_RED_Timestamps\"])\n",
    "        maximum_infra_red_timestamp = max(video_row[\"PPG_IR_Timestamps\"])\n",
    "\n",
    "        maximum_timestamp = max(maximum_timestamp, maximum_green_timestamp, maximum_red_timestamp, maximum_infra_red_timestamp)\n",
    "\n",
    "    return maximum_timestamp"
   ],
   "id": "34dbfa82073c188",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_range(values: np.ndarray, multiplier: float) -> list[float]:\n",
    "    min_value = min(values)\n",
    "    max_value = max(values)\n",
    "\n",
    "    value_range = max_value - min_value\n",
    "    mid_point = min_value + value_range / 2\n",
    "\n",
    "    min_limit = mid_point - (value_range / 2) * multiplier\n",
    "    max_limit = mid_point + (value_range / 2) * multiplier\n",
    "\n",
    "    return [min_limit, max_limit]\n",
    "\n",
    "def plot_ppg_axis(axis: plt.Axes, video_row: pd.Series, data_prefix: str, colour: str, x_limits: list[float], plot_index: list[int]):\n",
    "    timestamps = video_row[f\"{data_prefix}_Timestamps\"]\n",
    "    values = video_row[f\"{data_prefix}_Values\"]\n",
    "\n",
    "    axis.plot(timestamps, values, c = colour)\n",
    "\n",
    "    y_limits = get_range(values, 1.1)\n",
    "\n",
    "    axis.set_autoscale_on(False)\n",
    "    axis.set_xlim(x_limits[0], x_limits[1])\n",
    "    axis.set_ylim(y_limits[0], y_limits[1])\n",
    "\n",
    "    plot_index[0] += 1\n",
    "\n",
    "def seperator(plot_index: list[int]):\n",
    "    plot_index[0] += 1"
   ],
   "id": "3f36e41735fac30c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_raw_ppg_data(session_id: str, videos: pd.DataFrame):\n",
    "    figure_row_count = len(videos) * 3 + len(videos) - 1\n",
    "    figure = plt.figure(figsize=(80, 30))\n",
    "    figure.suptitle(f\"Session: {session_id}\", fontsize=16)\n",
    "    figure_grid_space = gridspec.GridSpec(figure_row_count, 1)\n",
    "\n",
    "    x_limits = [0, get_maximum_timestamp(videos)]\n",
    "\n",
    "    #Plot the data\n",
    "    plot_index: list[int] = [0]\n",
    "    for video_index, video_row in videos.iterrows():\n",
    "        video_id = video_row[\"Video_ID\"]\n",
    "\n",
    "        # Plot the green light stream\n",
    "        green_axis = figure.add_subplot(figure_grid_space[plot_index[0]])\n",
    "        plot_ppg_axis(green_axis, video_row, \"PPG_GRN\", \"green\", x_limits, plot_index)\n",
    "\n",
    "        # Plot the red light stream\n",
    "        red_axis = figure.add_subplot(figure_grid_space[plot_index[0]])\n",
    "        plot_ppg_axis(red_axis, video_row, \"PPG_RED\", \"orange\", x_limits, plot_index)\n",
    "\n",
    "        # Plot the orange light stream\n",
    "        infra_red_axis = figure.add_subplot(figure_grid_space[plot_index[0]])\n",
    "        plot_ppg_axis(infra_red_axis, video_row, \"PPG_IR\", \"red\", x_limits, plot_index)\n",
    "\n",
    "        # Draw Grouping Info\n",
    "        red_axis.text(-0.015, 0.5, video_id, transform=red_axis.transAxes, rotation = 90, ha='right', va='center', fontsize=12, color='black')\n",
    "        #line = ConnectionPatch(xyA=(0.5, 1.0), coordsA='axes fraction', xyB=(0.5, 0.0), coordsB='axes fraction', axesA=green_axis, axesB=infra_red_stream, color='black',linewidth=2)\n",
    "        #figure.add_artist(line)\n",
    "\n",
    "        # Add the breaker\n",
    "        seperator(plot_index)\n",
    "\n",
    "    plt.subplots_adjust(left=0.05, right= 0.99, top=0.95, bottom=0.05, hspace=0.6)\n",
    "    plt.savefig(f\"V:/Exports/{session_id} PPG Data.png\")\n",
    "    plt.close()\n",
    "\n",
    "    Log.message(f\"Saved File: {session_id} PPG Data.png\")"
   ],
   "id": "c1d6f8b11088d715",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process():\n",
    "    for _, row in _experiment_analytics.analytics_dataframe.iterrows():\n",
    "        session_id = row[\"Session_ID\"]\n",
    "        session_analytics = row[\"Analysis_Object\"]\n",
    "\n",
    "        session_video_data = video_data()\n",
    "        populate_video_data(session_analytics, session_video_data)\n",
    "        plot_raw_ppg_data(session_id, session_video_data)\n",
    "\n",
    "process()"
   ],
   "id": "515c7cc9ab5a401c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "timestamp_filter = TimestampStreamFilter(11528.00403109542, 11585.220626990775)\n",
    "subset = stream_analytics.get_filtered_subset(timestamp_filter)\n",
    "\n",
    "stream = stream_analytics.stream_data_dictionary[\"PPG_IR\"]\n",
    "\n",
    "_values = np.array(stream[\"Value\"].tolist())\n",
    "_timestamps = stream[\"Timestamp\"].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(_timestamps, _values)\n",
    "\n",
    "plt.savefig(\"V:/PPG_IR.png\")\n",
    "\n",
    "\"[Video: “Little girl being rescued by RNLI”, Event: VideoStart]\"\n",
    "\"\"\""
   ],
   "id": "9b8661252c74cb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "for i, video in enumerate(videos):\n",
    "    base_row = i * 4  # 3 plots + 1 spacer\n",
    "    for j in range(3):\n",
    "        ax = fig.add_subplot(gs[base_row + j])\n",
    "        ax.plot(x, ppg_ir, label=plot_labels[j], color=colors[j])\n",
    "        if j == 1:\n",
    "            ax.text(-0.025, 0.5, plot_labels[j], transform=ax.transAxes, rotation = 90, ha='right', va='center', fontsize=12, color='black')\n",
    "        ax.legend()\n",
    "\n",
    "axes = fig.get_axes()\n",
    "con = ConnectionPatch(xyA=(0.5, 1.0), coordsA='axes fraction', xyB=(0.5, 0.0), coordsB='axes fraction', axesA=axes[0], axesB=axes[1], color='black',linewidth=2)\n",
    "\n",
    "fig.add_artist(con)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(left=0.05, right= 0.95, top=0.95, bottom=0.05, hspace=0.6)\n",
    "plt.savefig('V:/test.png')\n",
    "plt.show()\n",
    "\"\"\""
   ],
   "id": "69d13d05f1aba03f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "# Simulated PPG data\n",
    "x = np.linspace(0, 10, 100)\n",
    "ppg_ir = np.sin(x)\n",
    "ppg_grn = np.cos(x)\n",
    "ppg_red = np.sin(x + np.pi/4)\n",
    "\n",
    "videos = ['Video 1', 'Video 2', 'Video 3']\n",
    "colors = ['PPG_IR', 'PPG_GRN', 'PPG_RED']\n",
    "signals = [ppg_ir, ppg_grn, ppg_red]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(10, 8), sharex=True)\n",
    "fig.suptitle('Person 1', fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(x, ppg_ir, label='PPG_IR')\n",
    "    ax.plot(x, ppg_grn, label='PPG_GRN')\n",
    "    ax.plot(x, ppg_red, label='PPG_RED')\n",
    "    ax.set_title(videos[i])\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "\n",
    "axes[-1].set_xlabel('Time (s)')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\"\"\""
   ],
   "id": "dd93ac8fa15beae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "videos = ['Video 1', 'Video 2', 'Video 3']\n",
    "\n",
    "fig, axes = plt.subplots(len(videos) * 3, 1, figsize=(20, 15), sharex=True)\n",
    "plt.suptitle(f'Person {i+1}', fontsize=16)\n",
    "\n",
    "for i, video in enumerate(videos):\n",
    "    subplot_index = i * 3\n",
    "    axes[subplot_index].title.set_text(f'Video {i}')\n",
    "    axes[subplot_index].plot(x, ppg_ir, label='PPG_GRN', c = 'green')\n",
    "    axes[subplot_index + 1].plot(x, ppg_ir, label='PPG_RED', c = 'orange')\n",
    "    axes[subplot_index + 2].plot(x, ppg_ir, label='PPG_IR', c = 'red')\n",
    "\n",
    "for _, axis in enumerate(axes): axis.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\""
   ],
   "id": "24309c4c0f0223c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "\n",
    "videos = ['Video 1', 'Video 2', 'Video 3']\n",
    "x = np.linspace(0, 10, 100)\n",
    "ppg_ir = np.sin(x)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "gs = gridspec.GridSpec(11, 1, height_ratios=[1]*3 + [0.2] + [1]*3 + [0.2] + [1]*3)\n",
    "fig.suptitle('Person 1', fontsize=16)\n",
    "\n",
    "plot_labels = ['PPG_GRN', 'PPG_RED', 'PPG_IR']\n",
    "colors = ['green', 'orange', 'red']\n",
    "\n",
    "for i, video in enumerate(videos):\n",
    "    base_row = i * 4  # 3 plots + 1 spacer\n",
    "    for j in range(3):\n",
    "        ax = fig.add_subplot(gs[base_row + j])\n",
    "        ax.plot(x, ppg_ir, label=plot_labels[j], color=colors[j])\n",
    "        if j == 1:\n",
    "            ax.text(-0.025, 0.5, plot_labels[j], transform=ax.transAxes, rotation = 90, ha='right', va='center', fontsize=12, color='black')\n",
    "\n",
    "            line = FancyArrowPatch((-0.02, -1.5), (-0.02, 2.5), transform=ax.transAxes, arrowstyle='-', linewidth=1, color='black')\n",
    "            fig.patches.append(line)\n",
    "        ax.legend()\n",
    "\n",
    "axes = fig.get_axes()\n",
    "con = ConnectionPatch(\n",
    "    xyA=(0.5, 1.0), coordsA='axes fraction',  # Top center of ax1\n",
    "    xyB=(0.5, 0.0), coordsB='axes fraction',  # Bottom center of ax2\n",
    "    axesA=axes[0], axesB=axes[1],\n",
    "    color='black', linewidth=2\n",
    ")\n",
    "\n",
    "fig.add_artist(con)\n",
    "\n",
    "\n",
    "plt.subplots_adjust(left=0.05, right= 0.95, top=0.95, bottom=0.05, hspace=0.6)\n",
    "plt.savefig('V:/test.png')\n",
    "plt.show()\n",
    "\"\"\""
   ],
   "id": "2f16ab94816ccd2e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
