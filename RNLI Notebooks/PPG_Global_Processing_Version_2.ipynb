{
 "cells": [
  {
   "cell_type": "code",
   "id": "5d6c27fd5ed2ab43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T16:05:52.789201Z",
     "start_time": "2025-08-11T16:05:52.735119Z"
    }
   },
   "source": "%reset -f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T16:05:54.209017Z",
     "start_time": "2025-08-11T16:05:53.369548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "from matplotlib import patches\n",
    "\n",
    "from MINE.Log import Log\n",
    "from MINE.Analysis import SessionAnalytics, ExperimentAnalytics\n",
    "from MINE.StreamFilter import IStreamFilter, TimestampStreamFilter\n",
    "from MINE.SessionFilters import ISessionFilter, ContainsStreamSessionFilter, ContainsMarkersSessionFilter\n",
    "from MINE.StreamProcessing import StreamProcesses\n",
    "from MINE.StreamOutput import StreamOutput\n",
    "from numpy.typing import NDArray"
   ],
   "id": "a3a9e8969ea22235",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T16:05:54.292131Z",
     "start_time": "2025-08-11T16:05:54.286883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ProjectData:\n",
    "    def __init__(self):\n",
    "        self.video_dictionary: dict[str, VideoData] = {}\n",
    "        self.participant_dictionary: dict[str, ParticipantData] = {}\n",
    "\n",
    "class ParticipantData:\n",
    "    def __init__(self):\n",
    "        self.participant_id: str | None = None\n",
    "        self.colour: str | None = None\n",
    "        self.calibration_baseline_heartrate: float | None = None\n",
    "\n",
    "class VideoData:\n",
    "    def __init__(self):\n",
    "        #Video Meta-Data\n",
    "        self.video_id: str | None = None\n",
    "        self.video_start_time: float | None = None\n",
    "        self.video_end_time: float | None = None\n",
    "        self.localised_video_start_time: float | None = None\n",
    "        self.localised_video_end_time: float | None = None\n",
    "        self.video_duration: float | None = None\n",
    "        self.full_duration: float | None = None\n",
    "\n",
    "        #Session Entries\n",
    "        self.session_entries: dict[str, SessionVideoEntry] = {}\n",
    "\n",
    "        #Analytics\n",
    "        self.mean_baseline_heartrate: float | None = None\n",
    "        self.mean_video_heartrate: float | None = None\n",
    "        self.mean_baseline_deviation: float | None = None\n",
    "\n",
    "class SessionVideoEntry:\n",
    "    def __init__(self):\n",
    "        #Data\n",
    "        self.video_analytics: SessionAnalytics | None = None\n",
    "\n",
    "        #Heart Rate Data\n",
    "        self.baseline_heartrate: float | None = None\n",
    "        self.video_mean_heartrate: float | None = None\n",
    "        self.mean_baseline_deviation: float | None = None\n",
    "\n",
    "        #Dataframes\n",
    "        self.heartrate: pd.DataFrame | None = None\n",
    "        self.heartrate_baseline_deviation: pd.DataFrame | None = None"
   ],
   "id": "19ee027d15f53ebc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T16:05:54.950038Z",
     "start_time": "2025-08-11T16:05:54.945275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stream_filter() -> ContainsStreamSessionFilter:\n",
    "    return ContainsStreamSessionFilter([\n",
    "        \"Marker\",\n",
    "        \"PPG_GRN\",\n",
    "        \"PPG_RED\",\n",
    "        \"PPG_IR\",\n",
    "    ])\n",
    "\n",
    "def marker_filter() -> ContainsMarkersSessionFilter:\n",
    "    return ContainsMarkersSessionFilter(\"Marker\", [\n",
    "        \"Video: Be a floater, Event: VideoStart\",\n",
    "        \"Video: Be a floater, Event: VideoEnd\",\n",
    "        \"Video: RNLI Respect the water “Ladbible short film”, Event: VideoStart\",\n",
    "        \"Video: RNLI Respect the water “Ladbible short film”, Event: VideoEnd\",\n",
    "        \"Video: “Evans story”, Event: VideoStart\",\n",
    "        \"Video: “Evans story”, Event: VideoEnd\",\n",
    "        \"Video: “Little girl being rescued by RNLI”, Event: VideoStart\",\n",
    "        \"Video: “Little girl being rescued by RNLI”, Event: VideoEnd\",\n",
    "        \"Video: Alfie’s phone, Event: VideoStart\",\n",
    "        \"Video: Alfie’s phone, Event: VideoEnd\",\n",
    "        \"Video: “Float to Live”, Event: VideoStart\",\n",
    "        \"Video: “Float to Live”, Event: VideoEnd\",\n",
    "        \"Video: Respect the Water via the NWSF\\u202f‘make the right call’, Event: VideoStart\",\n",
    "        \"Video: Respect the Water via the NWSF\\u202f‘make the right call’, Event: VideoEnd\",\n",
    "        \"Video: “Seaside safety song”, Event: VideoStart\",\n",
    "        \"Video: “Seaside safety song”, Event: VideoEnd\",\n",
    "        \"Video: RNLI the breath test, Event: VideoStart\",\n",
    "        \"Video: RNLI the breath test, Event: VideoEnd\",\n",
    "        \"Video: RNLI Christmas bed-time story, Event: VideoStart\",\n",
    "        \"Video: RNLI Christmas bed-time story, Event: VideoEnd\",\n",
    "        \"Video: “RNLI: The heart-breaking story of Liam Hall”, Event: VideoStart\",\n",
    "        \"Video: “RNLI: The heart-breaking story of Liam Hall”, Event: VideoEnd\",\n",
    "    ])\n",
    "\n",
    "def participant_files() -> pd.DataFrame:\n",
    "    return pd.DataFrame(columns=[\"Participant_ID\", \"File_Path\"], data=[\n",
    "        [\"P01\",    \"/mnt/Data/Raw/RNLI Data/participant 1.xdf\"],\n",
    "        [\"P02\",    \"/mnt/Data/Raw/RNLI Data/participant 2.xdf\"],\n",
    "        [\"P03\",    \"/mnt/Data/Raw/RNLI Data/participant 3.xdf\"],\n",
    "        [\"P04.0\",  \"/mnt/Data/Raw/RNLI Data/participant 4.0.xdf\"],\n",
    "        [\"P04.1\",  \"/mnt/Data/Raw/RNLI Data/participant 4.1.xdf\"],\n",
    "        [\"P05\",             \"/mnt/Data/Raw/RNLI Data/participant 5.xdf\"],\n",
    "        [\"P06\",             \"/mnt/Data/Raw/RNLI Data/participant 6.xdf\"],\n",
    "        [\"P07\",             \"/mnt/Data/Raw/RNLI Data/participant 7.xdf\"],\n",
    "        [\"P08\",             \"/mnt/Data/Raw/RNLI Data/participant 8.xdf\"],\n",
    "        [\"P09\",             \"/mnt/Data/Raw/RNLI Data/participant 9.xdf\"],\n",
    "        [\"P10\",    \"/mnt/Data/Raw/RNLI Data/participant 10.xdf\"],\n",
    "        [\"P11\",    \"/mnt/Data/Raw/RNLI Data/participant 11.xdf\"],\n",
    "        [\"P12\",             \"/mnt/Data/Raw/RNLI Data/participant 12.xdf\"],\n",
    "        [\"P13\",             \"/mnt/Data/Raw/RNLI Data/participant 13.xdf\"],\n",
    "        [\"P14\",             \"/mnt/Data/Raw/RNLI Data/participant 14.xdf\"],\n",
    "        [\"P15\",    \"/mnt/Data/Raw/RNLI Data/participant 15.xdf\"],\n",
    "        [\"P16\",    \"/mnt/Data/Raw/RNLI Data/participant 16.xdf\"]\n",
    "    ])"
   ],
   "id": "9e0cddfa73998016",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T16:06:50.135973Z",
     "start_time": "2025-08-11T16:05:55.485987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_project_data: ProjectData = ProjectData()\n",
    "\n",
    "_experiment_analytics: ExperimentAnalytics = ExperimentAnalytics.create_from_paths(participant_files())\n",
    "_experiment_analytics: ExperimentAnalytics = _experiment_analytics.get_filtered_subset([\n",
    "    marker_filter(),\n",
    "    stream_filter()\n",
    "])"
   ],
   "id": "7d7bf7eb0a7ba109",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m[ Message ]\u001B[0m Processing: P01\n",
      "\u001B[33m[ Warning ]\u001B[0m Duplicate stream name found 'Marker', added to dataframe dictionary as 'Marker (Duplicate) 1'\n",
      "\u001B[94m[ Message ]\u001B[0m Processing: P02\n",
      "\u001B[33m[ Warning ]\u001B[0m Duplicate stream name found 'Marker', added to dataframe dictionary as 'Marker (Duplicate) 1'\n",
      "\u001B[94m[ Message ]\u001B[0m Processing: P03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 21: Calculated effective sampling rate 0.0000 Hz is different from specified rate 50.0000 Hz.\n",
      "Stream 20: Calculated effective sampling rate 59.8759 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33m[ Warning ]\u001B[0m Stream 'Av Rating Continuous' is empty. Skipping.\n",
      "\u001B[33m[ Warning ]\u001B[0m Stream 'AV Rating Changes' is empty. Skipping.\n",
      "\u001B[33m[ Warning ]\u001B[0m Stream 'Marker' is empty. Skipping.\n",
      "\u001B[94m[ Message ]\u001B[0m Processing: P04.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 23: Calculated effective sampling rate 0.0000 Hz is different from specified rate 50.0000 Hz.\n",
      "Stream 12: Calculated effective sampling rate 59.8216 Hz is different from specified rate 50.0000 Hz.\n",
      "Stream 10: Calculated effective sampling rate -0.0001 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33m[ Warning ]\u001B[0m Stream 'Marker' is empty. Skipping.\n",
      "\u001B[33m[ Warning ]\u001B[0m Stream 'SCR_RIS' is empty. Skipping.\n",
      "\u001B[33m[ Warning ]\u001B[0m Stream 'Av Rating Continuous' is empty. Skipping.\n",
      "\u001B[33m[ Warning ]\u001B[0m Stream 'AV Rating Changes' is empty. Skipping.\n",
      "\u001B[33m[ Warning ]\u001B[0m Stream 'SCR_AMP' is empty. Skipping.\n",
      "\u001B[94m[ Message ]\u001B[0m Processing: P04.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 2: Calculated effective sampling rate 59.8672 Hz is different from specified rate 50.0000 Hz.\n",
      "Stream 15: Calculated effective sampling rate 0.0000 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33m[ Warning ]\u001B[0m Stream 'AV Rating Changes' is empty. Skipping.\n",
      "\u001B[33m[ Warning ]\u001B[0m Stream 'Marker' is empty. Skipping.\n",
      "\u001B[33m[ Warning ]\u001B[0m Stream 'Av Rating Continuous' is empty. Skipping.\n",
      "\u001B[94m[ Message ]\u001B[0m Processing: P05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 15: Calculated effective sampling rate 59.8903 Hz is different from specified rate 50.0000 Hz.\n",
      "Stream 25: Calculated effective sampling rate 0.0000 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33m[ Warning ]\u001B[0m Stream 'Marker' is empty. Skipping.\n",
      "\u001B[33m[ Warning ]\u001B[0m Stream 'AV Rating Changes' is empty. Skipping.\n",
      "\u001B[33m[ Warning ]\u001B[0m Stream 'Av Rating Continuous' is empty. Skipping.\n",
      "\u001B[94m[ Message ]\u001B[0m Processing: P06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 19: Calculated effective sampling rate 59.8990 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m[ Message ]\u001B[0m Processing: P07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 5: Calculated effective sampling rate 59.8858 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m[ Message ]\u001B[0m Processing: P08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 7: Calculated effective sampling rate 59.8891 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m[ Message ]\u001B[0m Processing: P09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 3: Calculated effective sampling rate 59.8815 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m[ Message ]\u001B[0m Processing: P10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 20: Calculated effective sampling rate 59.8872 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m[ Message ]\u001B[0m Processing: P11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 5: Calculated effective sampling rate 59.8941 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m[ Message ]\u001B[0m Processing: P12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 12: Calculated effective sampling rate 59.9389 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m[ Message ]\u001B[0m Processing: P13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 5: Calculated effective sampling rate 59.9016 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m[ Message ]\u001B[0m Processing: P14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 3: Calculated effective sampling rate 59.9293 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m[ Message ]\u001B[0m Processing: P15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 10: Calculated effective sampling rate 20.6733 Hz is different from specified rate 25.0000 Hz.\n",
      "Stream 6: Calculated effective sampling rate 21.4140 Hz is different from specified rate 25.0000 Hz.\n",
      "Stream 12: Calculated effective sampling rate 20.6327 Hz is different from specified rate 25.0000 Hz.\n",
      "Stream 11: Calculated effective sampling rate 20.6268 Hz is different from specified rate 25.0000 Hz.\n",
      "Stream 19: Calculated effective sampling rate 59.9221 Hz is different from specified rate 50.0000 Hz.\n",
      "Stream 9: Calculated effective sampling rate 20.6154 Hz is different from specified rate 25.0000 Hz.\n",
      "Stream 15: Calculated effective sampling rate 20.9101 Hz is different from specified rate 25.0000 Hz.\n",
      "Stream 18: Calculated effective sampling rate 22.2426 Hz is different from specified rate 25.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m[ Message ]\u001B[0m Processing: P16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stream 8: Calculated effective sampling rate 59.9187 Hz is different from specified rate 50.0000 Hz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m[ Message ]\u001B[0m Skipping session 'P02' as it does not contain marker 'Video: Be a floater, Event: VideoStart'.\n",
      "\u001B[94m[ Message ]\u001B[0m Skipping session 'P04.0' as it does not contain marker 'Video: Be a floater, Event: VideoStart'.\n",
      "\u001B[94m[ Message ]\u001B[0m Skipping session 'P04.1' as it does not contain marker 'Video: Be a floater, Event: VideoStart'.\n",
      "\u001B[94m[ Message ]\u001B[0m Filtering sessions containing streams: ['Marker', 'PPG_GRN', 'PPG_RED', 'PPG_IR']\n",
      "\u001B[94m[ Message ]\u001B[0m Skipping session 'P01' as it does not contain stream 'PPG_GRN'.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T16:06:57.168401Z",
     "start_time": "2025-08-11T16:06:50.197935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def heartrate_calibration(session_analytics: SessionAnalytics, participant_data: ParticipantData, sample_duration: float = 20, sampling_step_count: float = 5):\n",
    "    marker_pairs = session_analytics.get_paired_markers(\"Marker\", \"Start\", \"End\")\n",
    "    heartbeat_calibration_row = marker_pairs[marker_pairs[\"Marker\"].str.contains(\"Heartbeat\")]\n",
    "\n",
    "    start_of_heartbeat_calibration = heartbeat_calibration_row.iloc[0][\"Start Timestamp\"]\n",
    "    end_of_heartbeat_calibration = heartbeat_calibration_row.iloc[0][\"End Timestamp\"]\n",
    "    calibration_duration = end_of_heartbeat_calibration - start_of_heartbeat_calibration\n",
    "\n",
    "    calibration_analytics: SessionAnalytics = session_analytics.get_filtered_subset([\n",
    "        TimestampStreamFilter(start_of_heartbeat_calibration, end_of_heartbeat_calibration)\n",
    "    ])\n",
    "\n",
    "    calibration_analytics.localise_timestamps(start_of_heartbeat_calibration)\n",
    "    peak_annotations_stream = calibration_analytics.stream_data_dictionary[\"PPG_GRN_Filtered_Peak_Annotations\"]\n",
    "\n",
    "    #region [ Calculate Heartrate Averages ]\n",
    "    min_bpm: float = float(\"inf\")\n",
    "    max_bpm: float = float(\"-inf\")\n",
    "\n",
    "    values: NDArray[float] = np.empty(0)\n",
    "    timestamps: NDArray[float] = np.empty(0)\n",
    "\n",
    "    sample_time = sample_duration / 2\n",
    "    while sample_time < (calibration_duration - (sample_duration / 2)):\n",
    "        peaks_subset = peak_annotations_stream[\n",
    "            (peak_annotations_stream[\"Timestamp\"] > (sample_time - (sample_duration / 2))) &\n",
    "            (peak_annotations_stream[\"Timestamp\"] < (sample_time + (sample_duration / 2)))\n",
    "        ]\n",
    "\n",
    "        bpm = len(peaks_subset) * (60 / sample_duration)\n",
    "\n",
    "        if bpm < min_bpm: min_bpm = bpm\n",
    "        if bpm > max_bpm: max_bpm = bpm\n",
    "\n",
    "        values = np.append(values, bpm)\n",
    "        timestamps = np.append(timestamps, sample_time)\n",
    "\n",
    "        sample_time = sample_time + sampling_step_count\n",
    "\n",
    "    bpm_dataframe = pd.DataFrame({\n",
    "        \"Timestamp\": timestamps,\n",
    "        \"Value\": values\n",
    "    })\n",
    "    #endregion\n",
    "\n",
    "    #region [ Calculate Calibrated Baseline ]\n",
    "    baseline_heartrate = bpm_dataframe[\"Value\"].mean()\n",
    "    #endregion\n",
    "\n",
    "    participant_data.calibration_baseline_heartrate = baseline_heartrate\n",
    "\n",
    "def participant_analysis():\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    _project_data.participant_dictionary = {}\n",
    "    for index, row in tqdm(_experiment_analytics.analytics_dataframe.iterrows(), total=_experiment_analytics.analytics_dataframe.shape[0], desc=\"Preparing Sessions for Analysis\"):\n",
    "        session_analytics: SessionAnalytics = row[\"Analysis_Object\"]\n",
    "        session_id: str = session_analytics.file_name\n",
    "\n",
    "        participant_data = _project_data.participant_dictionary[session_id] = ParticipantData()\n",
    "        participant_data.colour = colors[index % len(colors)]\n",
    "\n",
    "        #region [ Process Streams ]\n",
    "        session_analytics.localise_timestamps()\n",
    "\n",
    "        StreamProcesses.butterworth_filter(session_analytics, \"PPG_GRN\", \"PPG_GRN_Filtered\")\n",
    "        StreamProcesses.detect_ppg_peaks(session_analytics, \"PPG_GRN_Filtered\", \"PPG_GRN_Filtered_Peak_Annotations\")\n",
    "        #StreamProcesses.generate_peak_interval_duration_stream(session_analytics, \"PPG_GRN_Filtered_Peak_Annotations\", \"PPG_GRN_Peak_Intervals\")\n",
    "        #StreamProcesses.generate_interval_differences_stream(session_analytics, \"PPG_GRN_Peak_Intervals\", \"PPG_GRN_Peak_Interval_Differences\")\n",
    "\n",
    "        #StreamProcesses.generate_rmssd_stream(session_analytics, \"PPG_GRN_Peak_Interval_Differences\", \"PPG_GRN_RMSSD\")\n",
    "        #StreamProcesses.generate_sdnn_stream(session_analytics, \"PPG_GRN_Peak_Interval_Differences\", \"PPG_GRN_SDNN\")\n",
    "\n",
    "        #StreamProcesses.create_vectors_from_component_streams(session_analytics, \"ACC_X\", \"ACC_Y\", \"ACC_Z\", \"ACC_Vector\")\n",
    "        #StreamProcesses.calculate_magnitudes_from_vector_stream(session_analytics, \"ACC_Vector\", \"ACC_Magnitude\")\n",
    "\n",
    "        #StreamProcesses.create_vectors_from_component_streams(session_analytics, \"GYRO_X\", \"GYRO_Y\", \"GYRO_Z\", \"GYRO_Vector\")\n",
    "        #StreamProcesses.calculate_magnitudes_from_vector_stream(session_analytics, \"GYRO_Vector\", \"GYRO_Magnitude\")\n",
    "        #endregion\n",
    "\n",
    "        #region [ Calibration ]\n",
    "        heartrate_calibration(session_analytics, participant_data)\n",
    "        break\n",
    "        #endregion\n",
    "\n",
    "participant_analysis()"
   ],
   "id": "94c42774f4e55839",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing Sessions for Analysis:   0%|          | 0/13 [00:06<?, ?it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-11T16:10:35.630910Z",
     "start_time": "2025-08-11T16:10:35.625149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for index, row in tqdm(_experiment_analytics.analytics_dataframe.iterrows(), total=_experiment_analytics.analytics_dataframe.shape[0], desc=\"Preparing Sessions for Analysis\"):\n",
    "    session_analytics: SessionAnalytics = row[\"Analysis_Object\"]\n",
    "\n",
    "    sdnn = StreamProcesses.get_sdnn_sample_from_annotated_ppg(session_analytics, \"PPG_GRN_Filtered_Peak_Annotations\", 10, 40)\n",
    "    rmssd = StreamProcesses.get_rmssd_sample_from_annotated_ppg(session_analytics, \"PPG_GRN_Filtered_Peak_Annotations\", 10, 40)\n",
    "\n",
    "    print(f\"SDNN: {sdnn}\")\n",
    "    print(f\"RMSDD: {rmssd}\")\n",
    "    break"
   ],
   "id": "576849e03ad6a54b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing Sessions for Analysis:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDNN: 115.83987118522622\n",
      "RMSDD: 196.7238342526725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def retrieve_heartrate_data(video_data: VideoData, session_video_entry: SessionVideoEntry, sample_duration: float = 20, sampling_step_count: float = 5):\n",
    "    video_analytics: SessionAnalytics = session_video_entry.video_analytics\n",
    "    peak_annotations_stream = video_analytics.stream_data_dictionary[\"PPG_GRN_Filtered_Peak_Annotations\"]\n",
    "\n",
    "    #region [ Calculate Heartrate Averages ]\n",
    "    min_bpm: float = float(\"inf\")\n",
    "    max_bpm: float = float(\"-inf\")\n",
    "\n",
    "    values: NDArray[float] = np.empty(0)\n",
    "    timestamps: NDArray[float] = np.empty(0)\n",
    "\n",
    "    sample_time = (video_data.localised_video_start_time -60 + (sample_duration / 2))\n",
    "    while sample_time < (video_data.localised_video_end_time - (sample_duration / 2)):\n",
    "        peaks_subset = peak_annotations_stream[\n",
    "            (peak_annotations_stream[\"Timestamp\"] > (sample_time - (sample_duration / 2))) &\n",
    "            (peak_annotations_stream[\"Timestamp\"] < (sample_time + (sample_duration / 2)))\n",
    "        ]\n",
    "\n",
    "        bpm = len(peaks_subset) * (60 / sample_duration)\n",
    "\n",
    "        if bpm < min_bpm: min_bpm = bpm\n",
    "        if bpm > max_bpm: max_bpm = bpm\n",
    "\n",
    "        values = np.append(values, bpm)\n",
    "        timestamps = np.append(timestamps, sample_time)\n",
    "\n",
    "        sample_time = sample_time + sampling_step_count\n",
    "\n",
    "    bpm_dataframe = pd.DataFrame({\n",
    "        \"Timestamp\": timestamps,\n",
    "        \"Value\": values\n",
    "    })\n",
    "    #endregion\n",
    "\n",
    "    #region [ Calculate Baseline ]\n",
    "    baseline_sample_subset = bpm_dataframe[\n",
    "        (bpm_dataframe[\"Timestamp\"] > -30) &\n",
    "        (bpm_dataframe[\"Timestamp\"] < 0)\n",
    "    ]\n",
    "\n",
    "    baseline_heartrate = baseline_sample_subset[\"Value\"].mean()\n",
    "    #endregion\n",
    "\n",
    "    #region [ Calculate Average Video Heartrate ]\n",
    "    video_mean_sample_subset = bpm_dataframe[\n",
    "        (bpm_dataframe[\"Timestamp\"] > 0) &\n",
    "        (bpm_dataframe[\"Timestamp\"] < video_data.video_duration)\n",
    "    ]\n",
    "\n",
    "    video_mean_heartrate = video_mean_sample_subset[\"Value\"].mean()\n",
    "    #endregion\n",
    "\n",
    "    #region [ Calculate Heartrate Baseline Deviation ]\n",
    "    baseline_deviation_dataframe = pd.DataFrame({\n",
    "        \"Timestamp\": bpm_dataframe[\"Timestamp\"],\n",
    "        \"Value\": pd.Series(bpm_dataframe[\"Value\"]).apply(lambda value: value / baseline_heartrate)\n",
    "    })\n",
    "\n",
    "    mean_baseline_deviation:float = video_mean_heartrate / baseline_heartrate\n",
    "    #endregion\n",
    "\n",
    "    session_video_entry.baseline_heartrate = baseline_heartrate\n",
    "    session_video_entry.video_mean_heartrate = video_mean_heartrate\n",
    "    session_video_entry.mean_baseline_deviation = mean_baseline_deviation\n",
    "\n",
    "    session_video_entry.heartrate = bpm_dataframe\n",
    "    session_video_entry.heartrate_baseline_deviation = baseline_deviation_dataframe\n",
    "\n",
    "def add_session_to_video_entry(video_data: VideoData, session_analytics: SessionAnalytics):\n",
    "    session_video_entry: SessionVideoEntry = SessionVideoEntry()\n",
    "    session_video_entry.video_analytics = session_analytics.get_filtered_subset([\n",
    "        TimestampStreamFilter(video_data.video_start_time - 60, video_data.video_end_time)\n",
    "    ])\n",
    "\n",
    "    session_video_entry.video_analytics.localise_timestamps(video_data.video_start_time)\n",
    "\n",
    "    #region [ Process Video Data ]\n",
    "    retrieve_heartrate_data(video_data, session_video_entry)\n",
    "    #endregion\n",
    "\n",
    "    video_data.session_entries[session_video_entry.video_analytics.file_name] = session_video_entry\n",
    "\n",
    "def video_analysis():\n",
    "    _project_data.video_dictionary = {}\n",
    "    for session_analytics in tqdm(_experiment_analytics.analytics_dataframe[\"Analysis_Object\"], total=_experiment_analytics.analytics_dataframe.shape[0], desc=\"Generating Video Entries\"):\n",
    "\n",
    "        #region [ Get Paired Markers ]\n",
    "        marker_pairs = session_analytics.get_paired_markers(\"Marker\", \"VideoStart\", \"VideoEnd\")\n",
    "\n",
    "        \"\"\" Remove the tutorial videos from the analytics.\"\"\"\n",
    "        marker_pairs = marker_pairs[~marker_pairs['Marker'].str.contains('panda', case=False, na=False)]\n",
    "        marker_pairs = marker_pairs[~marker_pairs['Marker'].str.contains('spiders', case=False, na=False)]\n",
    "\n",
    "        \"\"\" Remove the first video from the analytics.\"\"\"\n",
    "        marker_pairs = marker_pairs[1:]\n",
    "        #endregion\n",
    "\n",
    "        for video_index, row in marker_pairs.iterrows():\n",
    "            #region [ Initialise Video Entry ]\n",
    "            if row[\"Marker\"] not in _project_data.video_dictionary:\n",
    "                video_data = VideoData()\n",
    "                video_data.video_id = row[\"Marker\"]\n",
    "                video_data.video_start_time = row[\"Start Timestamp\"]\n",
    "                video_data.video_end_time = row[\"End Timestamp\"]\n",
    "                video_data.localised_video_start_time = 0\n",
    "                video_data.localised_video_end_time = row[\"End Timestamp\"] - row[\"Start Timestamp\"]\n",
    "                video_data.video_duration = row[\"End Timestamp\"] - row[\"Start Timestamp\"]\n",
    "                video_data.full_duration = row[\"End Timestamp\"] - row[\"Start Timestamp\"] + 60\n",
    "\n",
    "                _project_data.video_dictionary[row[\"Marker\"]] = video_data\n",
    "            else:\n",
    "                video_data: VideoData = _project_data.video_dictionary[row[\"Marker\"]]\n",
    "            #endregion\n",
    "\n",
    "            add_session_to_video_entry(video_data, session_analytics)\n",
    "\n",
    "video_analysis()"
   ],
   "id": "c3568b6f23df74ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_experiment_averages():\n",
    "    for key, video_data in tqdm(_project_data.video_dictionary.items(), total= len(_project_data.video_dictionary), desc=\"Generating Global Dictionaries\"):\n",
    "        video_data.mean_baseline_heartrate = statistics.mean([entry.baseline_heartrate for entry in video_data.session_entries.values()])\n",
    "        video_data.mean_video_heartrate = statistics.mean([entry.video_mean_heartrate for entry in video_data.session_entries.values()])\n",
    "        video_data.mean_baseline_deviation = statistics.mean([entry.mean_baseline_deviation for entry in video_data.session_entries.values()])\n",
    "\n",
    "process_experiment_averages()"
   ],
   "id": "a32e79ee81a7ead1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_heartrate_subfigure(video_data: VideoData, axis: plt.Axes):\n",
    "    for keys, session_video_entry in video_data.session_entries.items():\n",
    "        heartrate_dataframe = session_video_entry.heartrate\n",
    "\n",
    "        colour = _project_data.participant_dictionary[keys].colour\n",
    "        axis.plot(heartrate_dataframe[\"Timestamp\"], heartrate_dataframe[\"Value\"], c = colour)\n",
    "\n",
    "    axis.axhline(y=video_data.mean_baseline_heartrate, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "    axis.axhline(y=video_data.mean_video_heartrate, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    axis.title.set_text(\"Averaged Heartrate\")\n",
    "    axis.set_ylim(50, 100)\n",
    "\n",
    "    axis.fill_between([-40, 0], axis.get_ylim()[0], axis.get_ylim()[1], color='red', alpha=0.1)\n",
    "\n",
    "def plot_heartrate_deviation_subfigure(video_data: VideoData, axis: plt.Axes):\n",
    "    for keys, session_video_entry in video_data.session_entries.items():\n",
    "        heartrate_baseline_deviation_dataframe = session_video_entry.heartrate_baseline_deviation\n",
    "\n",
    "        colour = _project_data.participant_dictionary[keys].colour\n",
    "        axis.plot(heartrate_baseline_deviation_dataframe[\"Timestamp\"], heartrate_baseline_deviation_dataframe[\"Value\"], c = colour)\n",
    "\n",
    "    axis.axhline(y=1, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "    axis.axhline(y=video_data.mean_video_heartrate / video_data.mean_baseline_heartrate, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    axis.title.set_text(\"Averaged Heartrate Deviation from Baseline\")\n",
    "\n",
    "    axis.fill_between([-40, 0], axis.get_ylim()[0], axis.get_ylim()[1], color='red', alpha=0.1)\n",
    "\n",
    "def plot_gyroscope_subfigure(video_data: VideoData, axis: plt.Axes):\n",
    "    for keys, session_video_entry in video_data.session_entries.items():\n",
    "        gyroscope_magnitude_stream = session_video_entry.video_analytics.stream_data_dictionary[\"GYRO_Magnitude\"]\n",
    "\n",
    "        colour = _project_data.participant_dictionary[keys].colour\n",
    "        axis.plot(gyroscope_magnitude_stream[\"Timestamp\"], gyroscope_magnitude_stream[\"Value\"], c = colour)\n",
    "\n",
    "    axis.title.set_text(\"Gyroscope Magnitude\")\n",
    "\n",
    "def plot_accelerometer_subfigure(video_data: VideoData, axis: plt.Axes):\n",
    "    for keys, session_video_entry in video_data.session_entries.items():\n",
    "        accelerometer_magnitude_stream = session_video_entry.video_analytics.stream_data_dictionary[\"ACC_Magnitude\"]\n",
    "\n",
    "        colour = _project_data.participant_dictionary[keys].colour\n",
    "        axis.plot(accelerometer_magnitude_stream[\"Timestamp\"], accelerometer_magnitude_stream[\"Value\"], c = colour)\n",
    "\n",
    "    axis.title.set_text(\"Accelerometer Magnitude\")\n",
    "\n",
    "def plot_markers(video_data: VideoData, axes: list[plt.Axes]):\n",
    "    for axis in axes:\n",
    "        axis.axvline(x=0, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "        text_position: float = axis.get_ylim()[0]\n",
    "\n",
    "        axis.text(-60, text_position, \"Calibration Start\", horizontalalignment='center', verticalalignment='center')\n",
    "        axis.text(0, text_position, \"Video Start\", horizontalalignment='center', verticalalignment='center')\n",
    "        axis.text(video_data.localised_video_end_time, text_position, \"Video End\", horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "def plot_heartrate_variability_subfigure(video_data: VideoData, axis: plt.Axes):\n",
    "    for keys, session_video_entry in video_data.session_entries.items():\n",
    "        heartrate_variability_stream = session_video_entry.video_analytics.stream_data_dictionary[\"PPG_GRN_HRV\"]\n",
    "\n",
    "        colour = _project_data.participant_dictionary[keys].colour\n",
    "        axis.plot(heartrate_variability_stream[\"Timestamp\"], heartrate_variability_stream[\"Value\"], c = colour)\n",
    "    axis.title.set_text(\"Heart Rate Variability\")\n",
    "\n",
    "def generate_per_video_figures():\n",
    "    figure_rows = 5\n",
    "    video_index = 0\n",
    "    for key, video_data in tqdm(_project_data.video_dictionary.items(), total=len(_project_data.video_dictionary), desc=\"Generating Video Figures\"):\n",
    "        video_index += 1\n",
    "        figure, axes = plt.subplots(nrows=figure_rows, ncols=1, figsize=(video_data.full_duration * 0.5, figure_rows * 4), dpi=300)\n",
    "\n",
    "        plot_heartrate_subfigure(video_data, axes[0])\n",
    "        plot_heartrate_deviation_subfigure(video_data, axes[1])\n",
    "        plot_heartrate_variability_subfigure(video_data, axes[2])\n",
    "        plot_gyroscope_subfigure(video_data, axes[3])\n",
    "        plot_accelerometer_subfigure(video_data, axes[4])\n",
    "\n",
    "        plot_markers(video_data, axes)\n",
    "\n",
    "        for axis in axes: axis.set_xlim(-60, video_data.localised_video_end_time)\n",
    "\n",
    "        os.makedirs(f\"/mnt/Data/Analysis/Exports/Global Analysis\", exist_ok=True)\n",
    "        plt.savefig(f\"/mnt/Data/Analysis/Exports/Global Analysis/{video_index} Video Data.png\")\n",
    "        plt.close(figure)\n",
    "\n",
    "#generate_per_video_figures()"
   ],
   "id": "84485d543f5fdd6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_global_heartrate_calibration_to_video_calibration_figure():\n",
    "    calibration = [\"Calibration\"]\n",
    "    videos = list(_project_data.video_dictionary.keys())\n",
    "\n",
    "    participant_ids = list(_project_data.participant_dictionary.keys())\n",
    "    video_ids = calibration + videos\n",
    "\n",
    "    values = np.empty((len(video_ids), len(participant_ids)))\n",
    "\n",
    "\n",
    "    for participant_index in range(len(participant_ids)):\n",
    "        participant: str = participant_ids[participant_index]\n",
    "\n",
    "        participant_data: ParticipantData = _project_data.participant_dictionary[participant]\n",
    "\n",
    "        values[0, participant_index] = participant_data.calibration_baseline_heartrate\n",
    "\n",
    "    for video_index in range(len(videos)):\n",
    "        for participant_index in range(len(participant_ids)):\n",
    "            video: str = videos[video_index]\n",
    "            participant: str = participant_ids[participant_index]\n",
    "\n",
    "            video_data: VideoData = _project_data.video_dictionary[video]\n",
    "            participant_entry: SessionVideoEntry = video_data.session_entries[participant] if participant in video_data.session_entries else None\n",
    "\n",
    "            values[video_index + 1, participant_index] = participant_entry.baseline_heartrate if participant_entry else -1\n",
    "\n",
    "\n",
    "    figure, axis = plt.subplots(figsize=(16, 8), dpi=300)\n",
    "    im = axis.imshow(values, cmap=\"viridis\")\n",
    "\n",
    "    for i in range(len(video_ids)):\n",
    "        for j in range(len(participant_ids)):\n",
    "            text = f\"{int(values[i, j])}\"  # or use f\"{values[i, j]:.2f}\" for floats\n",
    "            axis.text(j, i, text, ha=\"center\", va=\"center\", color=\"white\")\n",
    "\n",
    "    row = 0\n",
    "    rect = patches.Rectangle(\n",
    "        (0 - 0.5, row - 0.5),  # x, y\n",
    "        len(participant_ids),                          # width\n",
    "        1,                                 # height\n",
    "        linewidth=1,\n",
    "        edgecolor='black',\n",
    "        facecolor='none'\n",
    "    )\n",
    "\n",
    "    axis.add_patch(rect)\n",
    "\n",
    "    axis.set_xticks(range(len(participant_ids)), labels=participant_ids, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    axis.set_yticks(range(len(video_ids)), labels=video_ids)\n",
    "\n",
    "    os.makedirs(f\"/mnt/Data/Analysis/Exports/Global Analysis\", exist_ok=True)\n",
    "    plt.savefig(f\"/mnt/Data/Analysis/Exports/Global Analysis/Calibration Comparison.png\")\n",
    "    plt.close(figure)\n",
    "\n",
    "#generate_global_heartrate_calibration_to_video_calibration_figure()"
   ],
   "id": "7108b1bdbdd1e662",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def retrieve_baseline_deviation_data(videos_keys: list[str], participants_keys: list[str]) -> NDArray[float]:\n",
    "    baseline_deviation: NDArray[float] = np.zeros((len(videos_keys), len(participants_keys) + 1))\n",
    "\n",
    "    for video_index in range(len(videos_keys)):\n",
    "        for participant_index in range(len(participants_keys)):\n",
    "            video: str = videos_keys[video_index]\n",
    "            participant: str = participants_keys[participant_index]\n",
    "\n",
    "            video_data: VideoData = _project_data.video_dictionary[video]\n",
    "            participant_entry: SessionVideoEntry = video_data.session_entries[participant] if participant in video_data.session_entries else None\n",
    "            baseline_deviation[video_index, participant_index] = participant_entry.mean_baseline_deviation if participant_entry else -1\n",
    "\n",
    "    for video_index in range(len(videos_keys)):\n",
    "        video: str = videos_keys[video_index]\n",
    "        video_data: VideoData = _project_data.video_dictionary[video]\n",
    "\n",
    "        baseline_deviation[video_index, -1] = video_data.mean_baseline_deviation\n",
    "\n",
    "    return baseline_deviation\n",
    "\n",
    "def display_cell_text(data: NDArray[float], axis: plt.Axes):\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            text = f\"{data[i, j]:.2f}\"  # or use f\"{values[i, j]:.2f}\" for floats\n",
    "            axis.text(j, i, text, ha=\"center\", va=\"center\", color=\"white\")\n",
    "\n",
    "def highlight_global_cells(participants: list[str], videos: list[str], axis: plt.Axes):\n",
    "    column = len(participants) - 1\n",
    "    row = 0\n",
    "    rect = patches.Rectangle(\n",
    "        (column - 0.5, row - 0.5),  # x, y\n",
    "        1,                          # width\n",
    "        len(videos),                                 # height\n",
    "        linewidth=1,\n",
    "        edgecolor='black',\n",
    "        facecolor='none'\n",
    "    )\n",
    "\n",
    "    axis.add_patch(rect)\n",
    "\n",
    "def generate_global_heartrate_deviation_figure():\n",
    "    videos = list(_project_data.video_dictionary.keys())\n",
    "    participants = list(_project_data.participant_dictionary.keys())\n",
    "    participants_with_global = participants + [\"Global\"]\n",
    "\n",
    "    data = retrieve_baseline_deviation_data(videos, participants)\n",
    "\n",
    "    figure, axis = plt.subplots(figsize=(16, 8), dpi=300)\n",
    "    im = axis.imshow(data, cmap=\"viridis\")\n",
    "\n",
    "    display_cell_text(data, axis)\n",
    "    highlight_global_cells(participants_with_global, videos, axis)\n",
    "\n",
    "    axis.set_xticks(range(len(participants_with_global)), labels=participants_with_global, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    axis.set_yticks(range(len(videos)), labels=videos)\n",
    "\n",
    "    os.makedirs(f\"/mnt/Data/Analysis/Exports/Global Analysis\", exist_ok=True)\n",
    "    plt.savefig(f\"/mnt/Data/Analysis/Exports/Global Analysis/Heartrate Deviation.png\")\n",
    "    plt.close(figure)\n",
    "\n",
    "#generate_global_heartrate_deviation_figure()"
   ],
   "id": "4ec8646fece844c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_participant_heartrate_variability(session_video_entry: SessionVideoEntry, key: str, axis: plt.Axes):\n",
    "    heartrate_variability_stream = session_video_entry.video_analytics.stream_data_dictionary[\"PPG_GRN_RMSSD\"]\n",
    "    #heartrate_variability_stream = session_video_entry.video_analytics.stream_data_dictionary[\"PPG_GRN_SDNN\"]\n",
    "\n",
    "    millisecond_values = heartrate_variability_stream[\"Value\"]\n",
    "\n",
    "    colour = _project_data.participant_dictionary[key].colour\n",
    "    axis.plot(heartrate_variability_stream[\"Timestamp\"], millisecond_values, c = colour)\n",
    "    axis.title.set_text(f\"Participant: {key}\")\n",
    "\n",
    "def plot_markers(video_data: VideoData, axes: list[plt.Axes]):\n",
    "    for axis in axes:\n",
    "        axis.axvline(x=0, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "        text_position: float = axis.get_ylim()[0]\n",
    "\n",
    "        axis.text(-60, text_position, \"Calibration Start\", horizontalalignment='center', verticalalignment='center')\n",
    "        axis.text(0, text_position, \"Video Start\", horizontalalignment='center', verticalalignment='center')\n",
    "        axis.text(video_data.localised_video_end_time, text_position, \"Video End\", horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "def generate_per_video_heartrate_variability():\n",
    "    figure_rows = len(_project_data.participant_dictionary.keys())\n",
    "    video_index = 0\n",
    "    for video_key, video_data in tqdm(_project_data.video_dictionary.items(), total=len(_project_data.video_dictionary), desc=\"Generating Video Figures\"):\n",
    "        video_index += 1\n",
    "        figure, axes = plt.subplots(nrows=figure_rows, ncols=1, figsize=(video_data.full_duration * 0.25, figure_rows * 2), dpi=300)\n",
    "\n",
    "        figure.suptitle(video_key)\n",
    "\n",
    "        for index, session_key in enumerate(_project_data.participant_dictionary.keys()):\n",
    "            if session_key not in video_data.session_entries: continue\n",
    "            session_video_entry: SessionVideoEntry = video_data.session_entries[session_key]\n",
    "            plot_participant_heartrate_variability(session_video_entry, session_key, axes[index])\n",
    "\n",
    "        plot_markers(video_data, axes)\n",
    "\n",
    "        for axis in axes: axis.set_xlim(-60, video_data.localised_video_end_time)\n",
    "\n",
    "        os.makedirs(f\"/mnt/Data/Analysis/Exports/Global Analysis\", exist_ok=True)\n",
    "        plt.savefig(f\"/mnt/Data/Analysis/Exports/Global Analysis/RMSSD {video_index} Video Data.png\")\n",
    "        plt.close(figure)\n",
    "\n",
    "        return\n",
    "\n",
    "generate_per_video_heartrate_variability()"
   ],
   "id": "41973c00e1358a87",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
