{
 "cells": [
  {
   "cell_type": "code",
   "id": "5d6c27fd5ed2ab43",
   "metadata": {},
   "source": "%reset -f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "\n",
    "from MINE.Log import Log\n",
    "from MINE.Analysis import SessionAnalytics, ExperimentAnalytics\n",
    "from MINE.StreamFilter import IStreamFilter, TimestampStreamFilter\n",
    "from MINE.SessionFilters import ISessionFilter, ContainsStreamSessionFilter, ContainsMarkersSessionFilter\n",
    "from MINE.StreamProcessing import StreamProcesses\n",
    "from MINE.StreamOutput import StreamOutput"
   ],
   "id": "a3a9e8969ea22235",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ProjectData:\n",
    "    def __init__(self):\n",
    "        self.video_data_dictionary: dict[str, VideoEntry] = {}\n",
    "        pass\n",
    "\n",
    "class VideoEntry:\n",
    "    def __init__(self):\n",
    "        #Video Meta-Data\n",
    "        self.video_id: str | None = None\n",
    "        self.full_duration: float | None = None\n",
    "        self.video_duration: float | None = None\n",
    "\n",
    "        #Biophysiological Data\n",
    "        self.gyroscope_data: list[pd.DataFrame] = []\n",
    "        self.accelerometer_data: list[pd.DataFrame] = []\n",
    "\n",
    "        #Heart Rate Data\n",
    "        self.baseline_heart_rates: list[float] = []\n",
    "        self.video_mean_heart_rates: list[float] = []\n",
    "        self.heart_rate: list[pd.DataFrame] = []\n",
    "        self.heart_rate_baseline_deviation: list[pd.DataFrame] = []\n",
    "        pass"
   ],
   "id": "19ee027d15f53ebc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def stream_filter() -> ContainsStreamSessionFilter:\n",
    "    return ContainsStreamSessionFilter([\n",
    "        \"Marker\",\n",
    "        \"PPG_GRN\",\n",
    "        \"PPG_RED\",\n",
    "        \"PPG_IR\",\n",
    "    ])\n",
    "\n",
    "def marker_filter() -> ContainsMarkersSessionFilter:\n",
    "    return ContainsMarkersSessionFilter(\"Marker\", [\n",
    "        \"Video: Be a floater, Event: VideoStart\",\n",
    "        \"Video: Be a floater, Event: VideoEnd\",\n",
    "        \"Video: RNLI Respect the water “Ladbible short film”, Event: VideoStart\",\n",
    "        \"Video: RNLI Respect the water “Ladbible short film”, Event: VideoEnd\",\n",
    "        \"Video: “Evans story”, Event: VideoStart\",\n",
    "        \"Video: “Evans story”, Event: VideoEnd\",\n",
    "        \"Video: “Little girl being rescued by RNLI”, Event: VideoStart\",\n",
    "        \"Video: “Little girl being rescued by RNLI”, Event: VideoEnd\",\n",
    "        \"Video: Alfie’s phone, Event: VideoStart\",\n",
    "        \"Video: Alfie’s phone, Event: VideoEnd\",\n",
    "        \"Video: “Float to Live”, Event: VideoStart\",\n",
    "        \"Video: “Float to Live”, Event: VideoEnd\",\n",
    "        \"Video: Respect the Water via the NWSF\\u202f‘make the right call’, Event: VideoStart\",\n",
    "        \"Video: Respect the Water via the NWSF\\u202f‘make the right call’, Event: VideoEnd\",\n",
    "        \"Video: “Seaside safety song”, Event: VideoStart\",\n",
    "        \"Video: “Seaside safety song”, Event: VideoEnd\",\n",
    "        \"Video: RNLI the breath test, Event: VideoStart\",\n",
    "        \"Video: RNLI the breath test, Event: VideoEnd\",\n",
    "        \"Video: RNLI Christmas bed-time story, Event: VideoStart\",\n",
    "        \"Video: RNLI Christmas bed-time story, Event: VideoEnd\",\n",
    "        \"Video: “RNLI: The heart-breaking story of Liam Hall”, Event: VideoStart\",\n",
    "        \"Video: “RNLI: The heart-breaking story of Liam Hall”, Event: VideoEnd\",\n",
    "    ])\n",
    "\n",
    "def participant_data() -> pd.DataFrame:\n",
    "    return pd.DataFrame(columns=[\"Participant_ID\", \"File_Path\"], data=[\n",
    "        [\"P01 - 535679\", \"V:/Data/Analysis/RNLI/participant 1.xdf\"],\n",
    "        [\"P02 - 888462\", \"V:/Data/Analysis/RNLI/participant 2.xdf\"],\n",
    "        [\"P03 - 499031\", \"V:/Data/Analysis/RNLI/participant 3.xdf\"],\n",
    "        [\"P04.0 - 832362\", \"V:/Data/Analysis/RNLI/participant 4.0.xdf\"],\n",
    "        [\"P04.1 - 832362\", \"V:/Data/Analysis/RNLI/participant 4.1.xdf\"],\n",
    "        [\"P05\", \"V:/Data/Analysis/RNLI/participant 5.xdf\"],\n",
    "        [\"P06\", \"V:/Data/Analysis/RNLI/participant 6.xdf\"],\n",
    "        [\"P07\", \"V:/Data/Analysis/RNLI/participant 7.xdf\"],\n",
    "        [\"P08\", \"V:/Data/Analysis/RNLI/participant 8.xdf\"],\n",
    "        [\"P09\", \"V:/Data/Analysis/RNLI/participant 9.xdf\"],\n",
    "        [\"P10 - 999149\", \"V:/Data/Analysis/RNLI/participant 10.xdf\"],\n",
    "        [\"P11 - 153327\", \"V:/Data/Analysis/RNLI/participant 11.xdf\"],\n",
    "        [\"P12\", \"V:/Data/Analysis/RNLI/participant 12.xdf\"],\n",
    "        [\"P13\", \"V:/Data/Analysis/RNLI/participant 13.xdf\"],\n",
    "        [\"P14\", \"V:/Data/Analysis/RNLI/participant 14.xdf\"],\n",
    "        [\"P15 - 156103\", \"V:/Data/Analysis/RNLI/participant 15.xdf\"],\n",
    "        [\"P16 - 701399\", \"V:/Data/Analysis/RNLI/participant 16.xdf\"]\n",
    "    ])"
   ],
   "id": "9e0cddfa73998016",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_project_data: ProjectData = ProjectData()\n",
    "\n",
    "_experiment_analytics: ExperimentAnalytics = ExperimentAnalytics.create_from_paths(participant_data())\n",
    "_experiment_analytics: ExperimentAnalytics = _experiment_analytics.get_filtered_subset([\n",
    "    marker_filter(),\n",
    "    stream_filter()\n",
    "])"
   ],
   "id": "7d7bf7eb0a7ba109",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def retrieve_gyroscope_data(video_analytics: SessionAnalytics, video_entry: VideoEntry):\n",
    "    gyroscope_x: pd.DataFrame = video_analytics.stream_data_dictionary[\"GYRO_X\"]\n",
    "    gyroscope_y: pd.DataFrame = video_analytics.stream_data_dictionary[\"GYRO_Y\"]\n",
    "    gyroscope_z: pd.DataFrame = video_analytics.stream_data_dictionary[\"GYRO_Z\"]\n",
    "\n",
    "    x_timestamps: np.ndarray = gyroscope_x['Timestamp'].to_numpy()\n",
    "    y_timestamps: np.ndarray = gyroscope_y['Timestamp'].to_numpy()\n",
    "    z_timestamps: np.ndarray = gyroscope_z['Timestamp'].to_numpy()\n",
    "\n",
    "    x_values: np.ndarray = np.concatenate(gyroscope_x['Value'].to_numpy())\n",
    "    y_values: np.ndarray = np.concatenate(gyroscope_y['Value'].to_numpy())\n",
    "    z_values: np.ndarray = np.concatenate(gyroscope_z['Value'].to_numpy())\n",
    "\n",
    "    idx_y: np.ndarray = np.abs(y_timestamps[:, None] - x_timestamps).argmin(axis=0)\n",
    "    idx_z: np.ndarray = np.abs(z_timestamps[:, None] - x_timestamps).argmin(axis=0)\n",
    "\n",
    "    aligned_y_values: np.ndarray = y_values[idx_y]\n",
    "    aligned_z_values: np.ndarray = z_values[idx_z]\n",
    "\n",
    "    magnitudes: np.ndarray = np.sqrt(np.square(x_values) + np.square(aligned_y_values) + np.square(aligned_z_values))\n",
    "    video_entry.gyroscope_data.append(pd.DataFrame({\n",
    "        \"Value\": magnitudes,\n",
    "        \"Timestamp\": x_timestamps\n",
    "    }))\n",
    "\n",
    "def retrieve_accelerometer_data(video_analytics: SessionAnalytics, video_entry: VideoEntry):\n",
    "    accelerometer_x: pd.DataFrame = video_analytics.stream_data_dictionary[\"ACC_X\"]\n",
    "    accelerometer_y: pd.DataFrame = video_analytics.stream_data_dictionary[\"ACC_Y\"]\n",
    "    accelerometer_z: pd.DataFrame = video_analytics.stream_data_dictionary[\"ACC_Z\"]\n",
    "\n",
    "    x_timestamps: np.ndarray = accelerometer_x['Timestamp'].to_numpy()\n",
    "    y_timestamps: np.ndarray = accelerometer_y['Timestamp'].to_numpy()\n",
    "    z_timestamps: np.ndarray = accelerometer_z['Timestamp'].to_numpy()\n",
    "\n",
    "    x_values: np.ndarray = np.concatenate(accelerometer_x['Value'].to_numpy())\n",
    "    y_values: np.ndarray = np.concatenate(accelerometer_y['Value'].to_numpy())\n",
    "    z_values: np.ndarray = np.concatenate(accelerometer_z['Value'].to_numpy())\n",
    "\n",
    "    idx_y: np.ndarray = np.abs(y_timestamps[:, None] - x_timestamps).argmin(axis=0)\n",
    "    idx_z: np.ndarray = np.abs(z_timestamps[:, None] - x_timestamps).argmin(axis=0)\n",
    "\n",
    "    aligned_y_values: np.ndarray = y_values[idx_y]\n",
    "    aligned_z_values: np.ndarray = z_values[idx_z]\n",
    "\n",
    "    magnitudes: np.ndarray = np.sqrt(np.square(x_values) + np.square(aligned_y_values) + np.square(aligned_z_values))\n",
    "    video_entry.accelerometer_data.append(pd.DataFrame({\n",
    "        \"Value\": magnitudes,\n",
    "        \"Timestamp\": x_timestamps\n",
    "    }))\n",
    "\n",
    "def retrieve_heart_rate_data(video_analytics: SessionAnalytics, video_entry: VideoEntry, sample_duration: float = 20, sampling_step_count: float = 5):\n",
    "    systolic_peaks = video_analytics.stream_data_dictionary[\"PPG_GRN_Filtered_Systolic_Peaks\"]\n",
    "    bpm_dataframe = pd.DataFrame(columns=[\"Timestamp\", \"BPM\"])\n",
    "\n",
    "    #region [ Calculate Average Heartrate ]\n",
    "    min_bpm: float = float(\"inf\")\n",
    "    max_bpm: float = 0\n",
    "\n",
    "    sample_time = -60 + (sample_duration / 2)\n",
    "    while sample_time < (video_entry.video_duration - (sample_duration / 2)):\n",
    "        peaks_subset = systolic_peaks[\n",
    "            (systolic_peaks[\"Timestamp\"] > (sample_time - (sample_duration / 2))) &\n",
    "            (systolic_peaks[\"Timestamp\"] < (sample_time + (sample_duration / 2)))\n",
    "        ]\n",
    "\n",
    "        bpm = len(peaks_subset) * (60 / sample_duration)\n",
    "\n",
    "        if bpm < min_bpm: min_bpm = bpm\n",
    "        if bpm > max_bpm: max_bpm = bpm\n",
    "\n",
    "        bpm_dataframe.loc[len(bpm_dataframe)] = [\n",
    "            sample_time,\n",
    "            bpm\n",
    "        ]\n",
    "\n",
    "        sample_time = sample_time + sampling_step_count\n",
    "    #endregion\n",
    "\n",
    "\n",
    "\n",
    "    #region [ Calculate Baseline ]\n",
    "    baseline_sample_subset = bpm_dataframe[\n",
    "        (bpm_dataframe[\"Timestamp\"] > -30) &\n",
    "        (bpm_dataframe[\"Timestamp\"] < 0)\n",
    "    ]\n",
    "\n",
    "    baseline_heartrate = baseline_sample_subset[\"BPM\"].mean()\n",
    "    #endregion\n",
    "\n",
    "    #region [ Calculate Average Video Heartrate ]\n",
    "    video_mean_sample_subset = bpm_dataframe[\n",
    "        (bpm_dataframe[\"Timestamp\"] > 0) &\n",
    "        (bpm_dataframe[\"Timestamp\"] < video_entry.video_duration)\n",
    "    ]\n",
    "\n",
    "    video_mean_heartrate = video_mean_sample_subset[\"BPM\"].mean()\n",
    "    #endregion\n",
    "\n",
    "    #region [ Calculate Heartrate Baseline Deviation ]\n",
    "    baseline_deviation_dataframe = pd.DataFrame({\n",
    "        \"Timestamp\": bpm_dataframe[\"Timestamp\"],\n",
    "        \"Deviation\": pd.Series(bpm_dataframe[\"BPM\"]).apply(lambda value: value / baseline_heartrate)\n",
    "    })\n",
    "    #endregion\n",
    "\n",
    "    video_entry.baseline_heart_rates.append(baseline_heartrate)\n",
    "    video_entry.video_mean_heart_rates.append(video_mean_heartrate)\n",
    "\n",
    "    video_entry.heart_rate.append(bpm_dataframe)\n",
    "    video_entry.heart_rate_baseline_deviation.append(baseline_deviation_dataframe)\n",
    "\n",
    "\n",
    "def generate_video_dictionary_entries(session_analytics: SessionAnalytics):\n",
    "    #region [ Create Video List For Session ]\n",
    "    marker_pairs = session_analytics.get_paired_markers(\"Marker\", \"VideoStart\", \"VideoEnd\")\n",
    "\n",
    "    marker_pairs = marker_pairs[~marker_pairs['Start Marker'].str.contains('panda', case=False, na=False)]\n",
    "    marker_pairs = marker_pairs[~marker_pairs['Start Marker'].str.contains('spiders', case=False, na=False)]\n",
    "    #endregion\n",
    "\n",
    "    gyro_durations = []\n",
    "    acc_durations = []\n",
    "    heart_rate_durations = []\n",
    "\n",
    "    for video_index, row in marker_pairs.iterrows():\n",
    "        #region [ Get Video Data ]\n",
    "        video_starting_marker = row[\"Start Marker\"]\n",
    "        video_start_time = row[\"Start Timestamp\"]\n",
    "        video_end_time = row[\"End Timestamp\"]\n",
    "        previous_calibration_start_time = video_start_time - 60\n",
    "        next_calibration_end_time = video_end_time + 60\n",
    "\n",
    "        video_analytics = session_analytics.get_filtered_subset([TimestampStreamFilter(previous_calibration_start_time, next_calibration_end_time)])\n",
    "        video_analytics.localise_timestamps(video_start_time)\n",
    "\n",
    "        video_end_time = video_end_time - video_start_time\n",
    "        previous_calibration_start_time = previous_calibration_start_time - video_start_time\n",
    "        next_calibration_end_time = next_calibration_end_time - video_start_time\n",
    "        video_start_time = 0\n",
    "\n",
    "        full_duration = video_end_time - previous_calibration_start_time\n",
    "        video_duration = video_end_time - video_start_time\n",
    "        #endregion\n",
    "\n",
    "        #region [ Add Video Data to Dataframe ]\n",
    "        video_data_dictionary = _project_data.video_data_dictionary\n",
    "\n",
    "        if video_starting_marker not in video_data_dictionary: video_data_dictionary[video_starting_marker] = VideoEntry()\n",
    "        video_entry = video_data_dictionary[video_starting_marker]\n",
    "        video_entry.video_id = video_starting_marker\n",
    "        video_entry.video_duration = video_duration\n",
    "        video_entry.full_duration = full_duration\n",
    "        #endregion\n",
    "\n",
    "        #region [ Retrieve Session Data ]\n",
    "        stopwatch_start_time = time.time()\n",
    "        retrieve_heart_rate_data(video_analytics, video_entry)\n",
    "        stopwatch_end_time = time.time()\n",
    "        heart_rate_durations.append(stopwatch_end_time - stopwatch_start_time)\n",
    "\n",
    "        stopwatch_start_time = time.time()\n",
    "        retrieve_gyroscope_data(video_analytics, video_entry)\n",
    "        stopwatch_end_time = time.time()\n",
    "        gyro_durations.append(stopwatch_end_time - stopwatch_start_time)\n",
    "\n",
    "        stopwatch_start_time = time.time()\n",
    "        retrieve_accelerometer_data(video_analytics, video_entry)\n",
    "        stopwatch_end_time = time.time()\n",
    "        acc_durations.append(stopwatch_end_time - stopwatch_start_time)\n",
    "        #endregion\n",
    "\n"
   ],
   "id": "1dcda70b9b7b1a10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_global_dictionaries():\n",
    "    for _, row in tqdm(_experiment_analytics.analytics_dataframe.iterrows(), total=_experiment_analytics.analytics_dataframe.shape[0], desc=\"Processing Sessions\"):\n",
    "        session_analytics: SessionAnalytics = row[\"Analysis_Object\"]\n",
    "        session_analytics.localise_timestamps()\n",
    "\n",
    "        StreamProcesses.butterworth_filter(session_analytics, \"PPG_GRN\", \"PPG_GRN_Filtered\")\n",
    "        StreamProcesses.detect_ppg_peaks(session_analytics, \"PPG_GRN_Filtered\")\n",
    "\n",
    "        generate_video_dictionary_entries(session_analytics)\n",
    "\n",
    "generate_global_dictionaries()"
   ],
   "id": "a32e79ee81a7ead1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_global_figure():\n",
    "    video_data_dictionary = _project_data.video_data_dictionary\n",
    "\n",
    "    video_index = 0\n",
    "    figure_rows = 5\n",
    "\n",
    "    for key, value in tqdm(video_data_dictionary.items(), total=len(video_data_dictionary), desc=\"Generating Video Figures\"):\n",
    "        video_entry: VideoEntry = value\n",
    "        video_index += 1\n",
    "\n",
    "        figure, axes = plt.subplots(nrows=figure_rows, ncols=1, figsize=(video_entry.full_duration * 0.5, figure_rows * 4), dpi=300)\n",
    "\n",
    "        for _, entry in enumerate(video_entry.gyroscope_data): axes[0].plot(entry[\"Timestamp\"], entry[\"Value\"])\n",
    "        for _, entry in enumerate(video_entry.accelerometer_data): axes[1].plot(entry[\"Timestamp\"], entry[\"Value\"])\n",
    "        for _, entry in enumerate(video_entry.heart_rate): axes[2].plot(entry[\"Timestamp\"], entry[\"BPM\"])\n",
    "        for _, entry in enumerate(video_entry.heart_rate_baseline_deviation): axes[3].plot(entry[\"Timestamp\"], entry[\"Deviation\"])\n",
    "\n",
    "        for _, axis in enumerate(axes): axis.vlines(0, axis.get_ylim()[0], axis.get_ylim()[1], linestyles='dashed', alpha=0.5, colors= \"black\")\n",
    "        for _, axis in enumerate(axes): axis.set_xlim(-60, video_entry.video_duration)\n",
    "\n",
    "        os.makedirs(f\"V:/Exports/Global Analysis\", exist_ok=True)\n",
    "        plt.savefig(f\"V:/Exports/Global Analysis/{video_index} Video Data.png\")\n",
    "        plt.close(figure)\n",
    "\n",
    "generate_global_figure()"
   ],
   "id": "84485d543f5fdd6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def view_data():\n",
    "    pass"
   ],
   "id": "7108b1bdbdd1e662",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
